{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>k-Nearest Neighbor (kNN) Classification</h2>\n",
    "<p>The kNN classifier consists of two stages:</p>\n",
    "<ul>\n",
    "<li> During training, the classifier takes the training data and simply remembers it.</li>\n",
    "<li> During testing, kNN classifies every test image by comparing to all training images and transferring the labels of the k most similar examples .</li>\n",
    "<li> The valur of k is cross-validated</li>\n",
    "</ul>\n",
    "\n",
    "### As for the dataset:\n",
    "<ul>\n",
    "<li> It contains 28709 training data points.</li>\n",
    "<li> And 7178 testing data points</li>\n",
    "<p>The data consists of 48x48 pixel grayscale images of faces. The faces have been automatically registered so that the face is more or less centered and occupies about the same amount of space in each image. The task is to categorize each face based on the emotion shown in the facial expression in to one of seven categories: `{0=Angry, 1=Disgust, 2=Fear, 3=Happy, 4=Sad, 5=Surprise, 6=Neutral}`.<br>\n",
    "<b>X_train.csv</b> contains 28709 rows(examples) and 2304(i.e 48 x 48) columns(columns represent the pixel values). <b>X_test.csv</b> contains 7178 rows and 2304 columns. <b>y_train.csv</b> & <b>y_test.csv</b> contains the numeric code ranging from 0 to 6 representing a certain emotion.</p>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some important packages\n",
    "from time import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from k_nearest_neighbor import KNearestNeighbor\n",
    "\n",
    "# matplotlib figures appear inline in the notebook rather than a new window\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10.0, 8.0)     # set default size of plots\n",
    "plt.rcParams[\"image.interpolation\"] = \"kaiser\"\n",
    "plt.rcParams[\"image.cmap\"] = \"gray\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X_train = np.genfromtxt(\"datasets/X_train.csv\", delimiter = \",\")\n",
    "y_train = np.genfromtxt(\"datasets/y_train.csv\", delimiter = \",\")\n",
    "X_test = np.genfromtxt(\"datasets/X_test.csv\", delimiter = \",\")\n",
    "y_test = np.genfromtxt(\"datasets/y_test.csv\", delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sanity check, print out the size of the training and test data\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset\n",
    "# Show a few exapmles of training images from each class\n",
    "classes = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 6\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(np.reshape(X_train[idx], (48, 48)))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsample the data for more efficient code execution\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "Xtrain = X_train[mask]\n",
    "ytrain = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = list(range(num_test))\n",
    "Xtest = X_test[mask]\n",
    "ytest = y_test[mask]\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will be using the kNN Classifier on the subsamples of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a kNN classifier instance\n",
    "# and train\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we would classify the test data with the kNN classifier. Recall that we can break down this step into two steps:</p>\n",
    "<ol>\n",
    "<li>First compute distances between all test examples and all training examples.</li>\n",
    "<li>Given these distances, for each test example, find the k nearest examples and have them vote for the label.</li>\n",
    "</ol>\n",
    "<p>Lets start with computing the distance matrix between all training and testing examples. For example, if there are <b>Ntr</b> training examples and <b>Nte</b> testing examples, this step should result in <b>Nte x Ntr</b> matrix where each element `(i, j)` is the `distance between i-th test example and j-th training example.`</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used time() to get to know about the time elapsed\n",
    "# no vectorization at all to speed up in compute_distances_two_loops(). So this is too slow\n",
    "start = time()\n",
    "distance_matrix = classifier.compute_distances_two_loops(Xtest)\n",
    "end = time()\n",
    "time_taken = end - start\n",
    "print(\"Time taken: {}\".format(time_taken))\n",
    "print(distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To visualize the distance matrix: each row is a single test example and its distances to training examples\n",
    "plt.figure(figsize = (18.0, 18.0))\n",
    "plt.imshow(distance_matrix, interpolation = \"nearest\") #kaiser would make it smooth\n",
    "# and we wont be able to visualize the pattern\n",
    "plt.show()\n",
    "# Black indicates low distances while white indicates high distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the function predict_labels.\n",
    "# using k = 1 (1 nearest neighbour)\n",
    "# Also print out the accuracy at particular value of k\n",
    "y_test_pred = classifier.predict_labels(distance_matrix, k = 1)\n",
    "# Compute and print function of corretly predicted labels\n",
    "num_correct = np.sum(y_test_pred == ytest)\n",
    "accuracy = float(num_correct / num_test)\n",
    "print(\"Predicted %d / %d correct -> accuracy: %f\"%(num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now change the value of k to 5\n",
    "y_test_pred = classifier.predict_labels(distance_matrix, k = 5)\n",
    "# Compute and print function of corretly predicted labels\n",
    "num_correct = np.sum(y_test_pred == ytest)\n",
    "accuracy = float(num_correct / num_test)\n",
    "print(\"Predicted %d / %d correct -> accuracy: %f\"%(num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can observe a slightly bad performance when k = 5. We need some sort of algorithm to find the best value of k (will be done below).`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets speed up distance matrix by using partial vectorization with one loop.\n",
    "# Implement the function compute_distances_one_loops\n",
    "start = time()\n",
    "distance_matrix_one = classifier.compute_distances_one_loop(Xtest)\n",
    "end = time()\n",
    "time_taken = end - start\n",
    "print(\"Time taken: {}\".format(time_taken))\n",
    "# There are many ways to check whether two matrices are similar; \n",
    "# one of the simplest is the Forbenius Norm . \n",
    "# The Frobenius norm of two matrices is the square root of the squared sum of differences of all elements.\n",
    "# Simply put you need to reshape the matrices into vectors and compute the Euclidean distance between them.\n",
    "difference = np.linalg.norm(distance_matrix - distance_matrix_one, ord = 'fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets implement the FULLY VECTORIZED one\n",
    "start = time()\n",
    "distance_matrix_two = classifier.compute_distances_no_loops(Xtest)\n",
    "end = time()\n",
    "print(\"Time Taken: {}\".format(end - start))\n",
    "difference = np.linalg.norm(distance_matrix - distance_matrix_two, ord = 'fro')\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The distance matrices are the same')\n",
    "else:\n",
    "    print('Uh-oh! The distance matrices are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`We can totally notice the change in excution time. Fully vectorized one was the best one.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "We have implemented the k-Nearest Neighbor classifier but we set the value k = 5 arbitrarily (although it made the accuracy worse). We will now determine the best value of this hyperparameter with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "k_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "                                                                        \n",
    "# Spliting up the training data into folds. After splitting, X_train_folds and\n",
    "# y_train_folds should each be lists of length num_folds, where          \n",
    "# y_train_folds[i] is the label vector for the points in X_train_folds[i].\n",
    "\n",
    "X_train_folds = np.array_split(Xtrain, num_folds)\n",
    "y_train_folds = np.array_split(ytrain, num_folds)\n",
    "\n",
    "\n",
    "# A dictionary holding the accuracies for different values of k that we find\n",
    "# when running cross-validation.\n",
    "k_to_accuracies = {}\n",
    "\n",
    "\n",
    "# Perform k-fold cross validation to find the best value of k. For each       \n",
    "# possible value of k, run the k-nearest-neighbor algorithm num_folds times.                              \n",
    "for k in k_choices:\n",
    "    for fold in range(num_folds):\n",
    "        valid_X_test = X_train_folds[fold]\n",
    "        valid_y_test = y_train_folds[fold]\n",
    "        fold_X_train = np.concatenate(X_train_folds[ : fold] + X_train_folds[fold + 1 : ])\n",
    "        fold_y_train = np.concatenate(y_train_folds[ : fold] + y_train_folds[fold + 1 : ])\n",
    "        \n",
    "        # create instance of kNN classifier and train it\n",
    "        a_classifier = KNearestNeighbor()\n",
    "        a_classifier.train(fold_X_train, fold_y_train)\n",
    "        \n",
    "        # Computing Distances\n",
    "        distance_for_folds = a_classifier.compute_distances_no_loops(valid_X_test)\n",
    "        fold_y_test_predict = a_classifier.predict_labels(distance_for_folds, k = k)\n",
    "        \n",
    "        # Now check accuracy\n",
    "        fold_num_correct = np.sum(fold_y_test_predict == valid_y_test)\n",
    "        fold_num_test = valid_X_test.shape[0]\n",
    "        fold_accuracy = float(fold_num_correct) / fold_num_test\n",
    "        \n",
    "        # Writing in the dictionary k_to_accuracies\n",
    "        k_to_accuracies[k] = k_to_accuracies.get(k, []) + [fold_accuracy]         \n",
    "\n",
    "# Print out the computed accuracies\n",
    "for k in sorted(k_to_accuracies):\n",
    "    for accuracy in k_to_accuracies[k]:\n",
    "        print('k = %d, accuracy = %f' % (k, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The accuracy is Heighest i.e 30.1% when k = 50. So we will be using that to predict.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A representation of how cross-validation accuracy varied with k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the raw observations\n",
    "for k in k_choices:\n",
    "    accuracies = k_to_accuracies[k]\n",
    "    plt.scatter([k] * len(accuracies), accuracies)\n",
    "\n",
    "# plot the trend line with error bars that correspond to standard deviation\n",
    "accuracies_mean = np.array([np.mean(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "accuracies_std = np.array([np.std(v) for k,v in sorted(k_to_accuracies.items())])\n",
    "plt.errorbar(k_choices, accuracies_mean, yerr=accuracies_std)\n",
    "plt.title('Cross-validation on k')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the cross-validation results above, choose the best value for k,   \n",
    "# retrain the classifier using all the training data, and test it on the test data\n",
    "best_k = 50\n",
    "\n",
    "classifier = KNearestNeighbor()\n",
    "classifier.train(Xtrain, ytrain)\n",
    "y_test_pred = classifier.predict(Xtest, k=best_k)\n",
    "\n",
    "# Compute and display the accuracy\n",
    "num_correct = np.sum(y_test_pred == ytest)\n",
    "accuracy = float(num_correct / num_test)\n",
    "print('Got %d / %d correct => accuracy: %f' % (num_correct, num_test, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>---------------------------------------------------------------------------------------------------------------------------------------------------------</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Lets use the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that we didnt mess up the actual dataset\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance of kNN for the whole dataset\n",
    "dataset_classifier = KNearestNeighbor()\n",
    "dataset_classifier.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the fully vectorized function to reduce the time taken.\n",
    "# also printing out the time taken, to run on the whole dataset\n",
    "start = time()\n",
    "dataset_classifier.compute_distances_no_loops(X_test)\n",
    "end = time()\n",
    "print(\"Time Taken: {}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and display the accuracy\n",
    "# and also compute the prediction time\n",
    "start = time()\n",
    "dataset_y_test_pred = dataset_classifier.predict(X_test, k = 50)\n",
    "end = time()\n",
    "dataset_num_correct = np.sum(dataset_y_test_pred == y_test)\n",
    "dataset_num_test = X_test.shape[0]\n",
    "dataset_accuracy = float(dataset_num_correct / dataset_num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Time taken: {}\".format(end - start))\n",
    "print('Got %d / %d correct => accuracy: %f' % (dataset_num_correct, dataset_num_test, dataset_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we acheived a total of 31.27% accuracy on using the whole dataset, which is pretty good, because we used a very naive ML Algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
